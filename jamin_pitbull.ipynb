{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b02c2762-27a4-4f46-ab60-1462314565e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import os\n",
    "import argparse\n",
    "import pickle\n",
    "import numpy as np\n",
    "import experiments as exp\n",
    "import VED\n",
    "import tensorflow as tf\n",
    "import preprocessing\n",
    "import standardize\n",
    "import importlib as imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84c89a20-a5c6-46e8-89ef-43984c9a95d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT = 'test_exp'\n",
    "\n",
    "# -------------------------------------------------------------------------------------------\n",
    "# -------------------------------------------------------------------------------------------\n",
    "\n",
    "# get experiment settings\n",
    "# assert np.isin(ARGS.exp_name, exp.experiments.keys()), \"no experiment with the name\" + ARGS.exp_name + \", current experiments:\" + exp.experiments.keys()\n",
    "experiment_settings = exp.get_experiment(EXPERIMENT)\n",
    "\n",
    "# -------------------------------------------------------------------------------------------\n",
    "# -------------------------------------------------------------------------------------------\n",
    "\n",
    "# set up random seed\n",
    "tf.keras.backend.clear_session()\n",
    "np.random.seed(experiment_settings[\"seed\"])\n",
    "# random.seed(experiment_settings[\"seed\"])\n",
    "tf.random.set_seed(experiment_settings[\"seed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0870647-484b-473b-8603-3a530a6d8efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/glade/campaign/cgd/cas/asphilli/ForceSMIP/ Omon tos CESM2\n",
      "/glade/campaign/cgd/cas/asphilli/ForceSMIP/ Omon tos CESM2\n",
      "/glade/campaign/cgd/cas/asphilli/ForceSMIP/ Amon pr CESM2\n",
      "/glade/campaign/cgd/cas/asphilli/ForceSMIP/ Amon pr CESM2\n"
     ]
    }
   ],
   "source": [
    "##### pre-process data\n",
    "# get random indices for training and validation\n",
    "# rng_seed = np.random.default_rng(experiment_settings[\"seed\"])\n",
    "# total_members = np.arange(np.sum(experiment_settings[\"nmembers\"])) # assuming this input is a list of train, val members\n",
    "# rnd_inds = []\n",
    "# for nmem in experiment_settings[\"nmembers\"]:\n",
    "#     rnd_inds.append(rng_seed.choice(total_members, nmem, replace=False))\n",
    "#     total_members = np.setdiff1d(total_members, rnd_inds)\n",
    "\n",
    "for ii, var in enumerate(experiment_settings[\"input_variable\"]):\n",
    "    # load the training and validation sets for this variable\n",
    "    At, Ft, It = preprocessing.make_data(models=experiment_settings[\"train_models\"], var=var,\n",
    "                                      timecut=experiment_settings[\"time_range\"], mems=experiment_settings[\"train_members\"])\n",
    "\n",
    "    Av, Fv, Iv = preprocessing.make_data(models=experiment_settings[\"val_models\"], var=var,\n",
    "                                      timecut=experiment_settings[\"time_range\"], mems=experiment_settings[\"val_members\"])\n",
    "    \n",
    "    \n",
    "    # put these into an array in the shape [samples, lat, lon, variable]\n",
    "    if ii == 0:\n",
    "        Atrain = At[:, :, :, np.newaxis]\n",
    "        Aval = Av[:, :, :, np.newaxis]\n",
    "        Ftrain = Ft[:, :, :, np.newaxis]\n",
    "        Fval = Fv[:, :, :, np.newaxis]\n",
    "        Itrain = It[:, :, :, np.newaxis]\n",
    "        Ival = Iv[:, :, :, np.newaxis]\n",
    "    else:\n",
    "        Atrain = np.concatenate([Atrain, At[:, :, :, np.newaxis]], axis=-1)\n",
    "        Aval = np.concatenate([Aval, Av[:, :, :, np.newaxis]], axis=-1)\n",
    "        Ftrain = np.concatenate([Ftrain, Ft[:, :, :, np.newaxis]], axis=-1)\n",
    "        Fval = np.concatenate([Fval, Fv[:, :, :, np.newaxis]], axis=-1)\n",
    "        Itrain = np.concatenate([Itrain, It[:, :, :, np.newaxis]], axis=-1)\n",
    "        Ival = np.concatenate([Ival, Iv[:, :, :, np.newaxis]], axis=-1)\n",
    "        \n",
    "    if var == experiment_settings[\"target_variable\"]:\n",
    "        target_ind = ii\n",
    "        \n",
    "# get the target variable\n",
    "Ftrain = Ftrain[:, :, :, target_ind]\n",
    "Itrain = Itrain[:, :, :, target_ind]\n",
    "    \n",
    "# -------------------------------------------------------------------------------------------\n",
    "# -------------------------------------------------------------------------------------------\n",
    "\n",
    "# get the correct evaluation data to predict\n",
    "Atest = preprocessing.make_eval_mem(evalmem=\"1H\",var=experiment_settings[\"target_variable\"],timecut=\"Tier1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d27256f9-601d-4e31-8b0e-fe96e3d58b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'standardize' from '/glade/u/home/egordon/ForceSMIP/standardize.py'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.reload(exp)\n",
    "imp.reload(standardize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ce54d2c-fcdc-43cc-aa6d-d3ed30ebd63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returning (Xtrain, Xval, Xtest, Ttrain, Tval)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Ftrain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# standardize and select 'internal' or 'forced'\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# jamin's datadoer here\u001b[39;00m\n\u001b[1;32m      3\u001b[0m Doer \u001b[38;5;241m=\u001b[39m standardize\u001b[38;5;241m.\u001b[39mDataDoer(Atrain, Aval, Atest, Ftrain, Fval, Itrain, Ival, experiment_settings)\n\u001b[0;32m----> 4\u001b[0m Xtrain, Xval, Xtest, Ttrain, Tval \u001b[38;5;241m=\u001b[39m \u001b[43mDoer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/glade/u/home/egordon/ForceSMIP/standardize.py:99\u001b[0m, in \u001b[0;36mDataDoer.do\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReturning (Xtrain, Xval, Xtest, Ttrain, Tval)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 99\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstandardize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselect()\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mremove_nans()\n",
      "File \u001b[0;32m/glade/u/home/egordon/ForceSMIP/standardize.py:30\u001b[0m, in \u001b[0;36mDataDoer.standardize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mistd  \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnanstd(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mItrain_us, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Add missing dimensions\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[43mFtrain\u001b[49m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m-\u001b[39m fmean\u001b[38;5;241m.\u001b[39mndim):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmean \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmean[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfstd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfstd[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Ftrain' is not defined"
     ]
    }
   ],
   "source": [
    "# standardize and select 'internal' or 'forced'\n",
    "# jamin's datadoer here\n",
    "Doer = standardize.DataDoer(Atrain, Aval, Atest, Ftrain, Fval, Itrain, Ival, experiment_settings)\n",
    "Xtrain, Xval, Xtest, Ttrain, Tval = Doer.do()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6481243c-f6d5-4789-98d1-c82d9adf3b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "ved, encoder, decoder = VED.build_VED(Xtrain, experiment_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b626fd-ece9-4caa-a20b-85307ad260f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "ved, encoder, decoder, history = VED.train_VED(Xtrain, Ttrain, Xval, Tval, experiment_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41433ada-26a2-493b-a6b5-8b3982319d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save trained model\n",
    "tf.keras.models.save_model(ved, os.path.join('saved_models', exp_name, exp_name+str(experiment_settings[\"seed\"])+\"_model\"), overwrite=False)\n",
    "ved.save_weights(os.path.join('saved_models', exp_name, exp_name+str(experiment_settings[\"seed\"])+\"_weights.h5\"))\n",
    "with open(os.path.join('saved_models', exp_name, exp_name+str(experiment_settings[\"seed\"])+\"_history.pickle\"), \"wb\") as handle:\n",
    "        pickle.dump(ved.history.history, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc095e3-88ff-492f-96b3-d608f20c389d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions and save standardized and unstandardized\n",
    "Ptrain = ved.predict(Xtrain)\n",
    "Pval = ved.predict(Xval)\n",
    "Ptest = ved.predict(Xtest)\n",
    "\n",
    "Ptrain_us, Pval_us, Ptest_us = Doer.unstandardize(Ptrain, Pval, Ptest)\n",
    "\n",
    "Ptrain_out = Atrain-Ptrain_us\n",
    "Pval_out = Aval-Pval_us\n",
    "Ptest_out = Atest-Ptest_us\n",
    "\n",
    "arr_name = 'saved_predictions/' + exp_name+str(experiment_settings[\"seed\"])+\"_preds.npz\"\n",
    "np.savez(arr_name,Ptrain=Ptrain_out,\n",
    "                  Pval=Pval_out,\n",
    "                  Ptest=Ptest_out,\n",
    "                  )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
